#!/bin/bash -l

## SLURM job submission script for running the encoder-decoder neural network script (unet.py)
##
## Request a single compute node containing 4 Pascal architecture GPUs

#SBATCH --nodes=1
#SBATCH --gres=gpu:4
#SBATCH --constraint=p100

## Specify the SLURM partition to be used and a miximum runtime of 1 hour

#SBATCH --time=01:00:00
#SBATCH --partition=gpuq-dev

## Give a run to the run and do not copy the login node environment settings onto the compute node

#SBATCH --job-name=weather
#SBATCH --account=pawsey0001
#SBATCH --export=NONE

# Set the name of the python script to be ran and the container image we will load/run

ML_SCRIPT=unet.py
CONTAINER=tensorflow/tensorflow:1.12.0-gpu-py3

# Set values to the configurable hyperparameters in the ML script

EPOCHS=40
BATCH_SIZE=64
LEARN_RATE=0.001
L2=0.00001
MIN_DELTA=0.01

##
##---- Do not change anything below this line ----
##

module load shifter
time srun -n 1 --export=ALL shifter run ${CONTAINER} python ${ML_SCRIPT} -e ${EPOCHS} -b ${BATCH_SIZE} -g 4 -l ${LEARN_RATE} -r ${L2} -m ${MIN_DELTA}

