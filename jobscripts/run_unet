#!/bin/bash -l

###-------------------------------------------------------------------------------------------------
###
###    SLURM settings 
###
###-------------------------------------------------------------------------------------------------

## Request a single compute node containing 4 Pascal architecture GPUs

#SBATCH --nodes=1
#SBATCH --gres=gpu:4
#SBATCH --constraint=p100

## Specify the SLURM partition to be used and a miximum runtime of 1 hour

#SBATCH --time=01:00:00
#SBATCH --partition=gpuq-dev

#SBATCH --reservation=nvpeertest

## Give a name to the run 

#SBATCH --job-name=ChannelCorr

## Set the user project ID and copy over all necessary variables from the login node environment

#SBATCH --account=pawsey0001
#SBATCH --export=NONE


###-------------------------------------------------------------------------------------------------
###
###    Run-specific settings 
###
###-------------------------------------------------------------------------------------------------

# Set the name of the python script to be run (the encoder/decoder model in this case)

ML_SCRIPT=basic_chan.py

# Set the name of the Docker container to be used for the run

CONTAINER=mxnet/python:1.3.0_gpu_cu92_py3

# Set values to the configurable hyperparameters in the ML script

EPOCHS=2
BATCH_SIZE=128
LEARN_RATE=0.001
L2=0.00001
MIN_DELTA=0.01


##====================================================================================================
##---------------------------    Do not change anything below this line    ---------------------------
##====================================================================================================

# set environment for container infrastructure

module load shifter
export RUN_CMD="shifter run ${CONTAINER} python3"

# determine number of GPUs present in SLURM allocation
IFS=',' read -ra gpus <<< "$CUDA_VISIBLE_DEVICES"

time srun -n 1 --export=ALL ${RUN_CMD} ${ML_SCRIPT} -e ${EPOCHS} -b ${BATCH_SIZE} -g ${#gpus[@]} -l ${LEARN_RATE} -r ${L2} -m ${MIN_DELTA}
