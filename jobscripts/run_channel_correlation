#!/bin/bash -l

## SLURM job submission script for running the channel correlation search script (basic_1chan.py) 
##
## Request a single compute node containing 1 Pascal architecture GPU

#SBATCH --nodes=1
#SBATCH --gres=gpu:1
#SBATCH --constraint=p100

## Specify the SLURM partition to be used and a miximum runtime of 1 hour

#SBATCH --time=01:00:00
#SBATCH --partition=gpuq-dev

## Give a run to the run and do not copy the login node environment settings onto the compute node

#SBATCH --job-name=channel_corr
#SBATCH --account=pawsey0001
#SBATCH --export=NONE

# Set the name of the python script to be ran and the container image we will load/run

ML_SCRIPT=basic_1chan.py
CONTAINER=tensorflow/tensorflow:1.12.0-gpu-py3

# Set values to the configurable hyperparameters in the ML script

EPOCHS=40
BATCH_SIZE=64
LEARN_RATE=0.001
CHANNELS=2

##
##---- Do not change anything below this line ----
##

module load shifter
time srun -n 1 --export=ALL shifter run ${CONTAINER} python ${ML_SCRIPT} -e ${EPOCHS} -b ${BATCH_SIZE} -g 1 -l ${LEARN_RATE} -c ${CHANNELS}

