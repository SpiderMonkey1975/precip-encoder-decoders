#!/bin/bash -l

## SLURM job submission script for running the encoder-decoder neural network script 

#SBATCH --nodes=1
#SBATCH --gres=gpu:1
#SBATCH --time=08:30:00
#SBATCH --partition=gpuq
#SBATCH --job-name=ERA5_Classifier
#SBATCH --account=director2107
#SBATCH --export=NONE


# Set the name of the python script to be ran and the container image we will load/run

ML_SCRIPT=era5_classification.py
CONTAINER=tensorflow/tensorflow:1.12.0-gpu-py3

# Set values to the configurable hyperparameters in the ML script

EPOCHS=100
BATCH_SIZE=8
LEARN_RATE=0.0001
VARIABLE=z
DATASET=au
NUM_FILTERS=16
NUM_HIDDEN_NODES=16
NUM_UNET_LAYERS=1

##====================================================================================================
##---------------------------    Do not change anything below this line    ---------------------------
##====================================================================================================

# set environment for container infrastructure
module load shifter
export RUN_CMD="shifter run ${CONTAINER} python"

# determine number of GPUs present in SLURM allocation
IFS=',' read -ra gpus <<< "$CUDA_VISIBLE_DEVICES"

time srun -n 1 --export=ALL -u ${RUN_CMD} ${ML_SCRIPT} -e ${EPOCHS} -b ${BATCH_SIZE} -g ${#gpus[@]} -l ${LEARN_RATE} -v ${VARIABLE} -d ${DATASET} -f ${NUM_FILTERS} -n ${NUM_HIDDEN_NODES} -y ${NUM_UNET_LAYERS}

